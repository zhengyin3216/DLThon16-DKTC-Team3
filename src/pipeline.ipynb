{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfa3877-c61a-4c10-9438-a1f712ed333f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (4.57.6)\n",
      "Requirement already satisfied: filelock in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: requests in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from transformers) (4.67.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jjeong3150/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages (from requests->transformers) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72e0d49-9a92-4652-aa62-dd7e83d51992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e173fc8-f133-4a2a-bc4d-2358ce921e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "# save_path = \"~/work/DKTC/\"\n",
    "save_path = \"../\"\n",
    "\n",
    "train_df = pd.read_csv(save_path + 'data/train_preprocseeing_0210_2.csv')\n",
    "test_df = pd.read_csv(save_path + 'data/test_preprocseeing_0210_3.csv')\n",
    "submission_df = pd.read_csv(save_path + 'data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea72cbe-d060-4a25-b893-20182340246c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid value '0' for dtype 'str'. Value should be a string or missing value, got 'int' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m협박 대화\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = \u001b[32m0\u001b[39m\n\u001b[32m      2\u001b[39m train_df.loc[train_df[\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33m갈취 대화\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m1\u001b[39m\n\u001b[32m      3\u001b[39m train_df.loc[train_df[\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33m직장 내 괴롭힘 대화\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/indexing.py:938\u001b[39m, in \u001b[36m_LocationIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    933\u001b[39m \u001b[38;5;28mself\u001b[39m._has_valid_setitem_indexer(key)\n\u001b[32m    935\u001b[39m iloc: _iLocIndexer = (\n\u001b[32m    936\u001b[39m     cast(\u001b[33m\"\u001b[39m\u001b[33m_iLocIndexer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33miloc\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj.iloc\n\u001b[32m    937\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m \u001b[43miloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/indexing.py:1953\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   1950\u001b[39m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[32m   1951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[32m   1952\u001b[39m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1955\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_single_block(indexer, value, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/indexing.py:2044\u001b[39m, in \u001b[36m_iLocIndexer._setitem_with_indexer_split_path\u001b[39m\u001b[34m(self, indexer, value, name)\u001b[39m\n\u001b[32m   2041\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2042\u001b[39m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[32m   2043\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/indexing.py:2181\u001b[39m, in \u001b[36m_iLocIndexer._setitem_single_column\u001b[39m\u001b[34m(self, loc, value, plane_indexer)\u001b[39m\n\u001b[32m   2171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype == np.void:\n\u001b[32m   2172\u001b[39m     \u001b[38;5;66;03m# This means we're expanding, with multiple columns, e.g.\u001b[39;00m\n\u001b[32m   2173\u001b[39m     \u001b[38;5;66;03m#     df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]})\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2176\u001b[39m     \u001b[38;5;66;03m# Here, we replace those temporary `np.void` columns with\u001b[39;00m\n\u001b[32m   2177\u001b[39m     \u001b[38;5;66;03m# columns of the appropriate dtype, based on `value`.\u001b[39;00m\n\u001b[32m   2178\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj.iloc[:, loc] = construct_1d_array_from_inferred_fill_value(\n\u001b[32m   2179\u001b[39m         value, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   2180\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2181\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplane_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/internals/managers.py:1503\u001b[39m, in \u001b[36mBlockManager.column_setitem\u001b[39m\u001b[34m(self, loc, idx, value, inplace_only)\u001b[39m\n\u001b[32m   1501\u001b[39m     col_mgr.setitem_inplace(idx, value)\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1503\u001b[39m     new_mgr = \u001b[43mcol_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1504\u001b[39m     \u001b[38;5;28mself\u001b[39m.iset(loc, new_mgr._block.values, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/internals/managers.py:604\u001b[39m, in \u001b[36mBaseBlockManager.setitem\u001b[39m\u001b[34m(self, indexer, value)\u001b[39m\n\u001b[32m    600\u001b[39m     \u001b[38;5;66;03m# No need to split if we either set all columns or on a single block\u001b[39;00m\n\u001b[32m    601\u001b[39m     \u001b[38;5;66;03m# manager\u001b[39;00m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msetitem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/internals/managers.py:442\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    445\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, [ax.view() \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1667\u001b[39m, in \u001b[36mEABackedBlock.setitem\u001b[39m\u001b[34m(self, indexer, value)\u001b[39m\n\u001b[32m   1664\u001b[39m check_setitem_lengths(indexer, value, values)\n\u001b[32m   1666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1667\u001b[39m     \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m = value\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m   1669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.dtype, IntervalDtype):\n\u001b[32m   1670\u001b[39m         \u001b[38;5;66;03m# see TestSetitemFloatIntervalWithIntIntervalValues\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/arrays/string_.py:863\u001b[39m, in \u001b[36mStringArray.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._readonly:\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot modify read-only array\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_convert_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m key = check_array_indexer(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m    866\u001b[39m scalar_key = lib.is_scalar(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/aiffel_learning_py312/lib/python3.12/site-packages/pandas/core/arrays/string_.py:837\u001b[39m, in \u001b[36mStringArray._maybe_convert_setitem_value\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    835\u001b[39m         value = \u001b[38;5;28mself\u001b[39m.dtype.na_value\n\u001b[32m    836\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    838\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid value \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Value should \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbe a string or missing value, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    840\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minstead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    841\u001b[39m         )\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    843\u001b[39m     value = extract_array(value, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: Invalid value '0' for dtype 'str'. Value should be a string or missing value, got 'int' instead."
     ]
    }
   ],
   "source": [
    "train_df.loc[train_df['class'] == '협박 대화', 'class'] = 0\n",
    "train_df.loc[train_df['class'] == '갈취 대화', 'class'] = 1\n",
    "train_df.loc[train_df['class'] == '직장 내 괴롭힘 대화', 'class'] = 2\n",
    "train_df.loc[train_df['class'] == '기타 괴롭힘 대화', 'class'] = 3\n",
    "#train_df.loc[train_df['class'] == '일반 대화', 'class'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b416f8c2-4569-4bb1-90aa-1add43445c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Class Distribution]\n",
      "class\n",
      "3    1010\n",
      "1     973\n",
      "2     970\n",
      "0     892\n",
      "Name: count, dtype: int64\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>어이 거기 예?? 너 말이야 너. 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘 돈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  \\\n",
       "0     0   \n",
       "1     0   \n",
       "2     3   \n",
       "3     1   \n",
       "4     1   \n",
       "\n",
       "                                                                         conversation  \n",
       "0  지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면 혼...  \n",
       "1  길동경찰서입니다. 9시 40분 마트에 폭발물을 설치할거다. 네? 똑바로 들어 한번만...    \n",
       "2  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어. 그만해. 니들 놀리는거 재미없...   \n",
       "3  어이 거기 예?? 너 말이야 너. 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘 돈...        \n",
       "4  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "print(\"[Class Distribution]\")\n",
    "print(train_df['class'].value_counts())\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# 데이터 예시\n",
    "display(train_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0aecb-ea07-40e4-9b33-35de7722511b",
   "metadata": {},
   "source": [
    "## 사전 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61b0b4c-8f47-47fc-b47a-e851fb20004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9845b657d7473ca0d200b5e5d94306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: klue/roberta-small\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\"klue/roberta-small\", num_labels=5)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5a7e5e-ca87-458c-a4cf-ab399bf01f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"add_cross_attention\": false,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"neuron\": {\n",
      "    \"auto_cast\": null,\n",
      "    \"auto_cast_type\": null,\n",
      "    \"compiler_type\": \"neuronx-cc\",\n",
      "    \"compiler_version\": \"2.19.8089.0+8ab9f450\",\n",
      "    \"disable_fallback\": false,\n",
      "    \"disable_fast_relayout\": false,\n",
      "    \"dynamic_batch_size\": false,\n",
      "    \"inline_weights_to_neff\": true,\n",
      "    \"input_names\": [\n",
      "      \"input_ids\",\n",
      "      \"attention_mask\"\n",
      "    ],\n",
      "    \"model_type\": \"roberta\",\n",
      "    \"optlevel\": \"2\",\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_names\": [\n",
      "      \"logits\"\n",
      "    ],\n",
      "    \"static_batch_size\": 1,\n",
      "    \"static_sequence_length\": 128,\n",
      "    \"task\": \"fill-mask\",\n",
      "    \"tensor_parallel_size\": 1\n",
      "  },\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torchscript\": true,\n",
      "  \"transformers_version\": \"5.1.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"klue/roberta-small\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374fc20e-1b53-4fff-82e7-b85fd7207122",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51e747c-8dfd-4f8f-8d09-0b1573705e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 235.73571239477968\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train_df['conversation']]\n",
    "sns.histplot(tokenizer_len)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_len)+2*np.std(tokenizer_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82062e58-e1a5-4c85-9494-e8c6cb93ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CleanTalkDataset(Dataset):\n",
    "    def __init__(self, data, labels, is_trainable, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []\n",
    "        self.labels = labels\n",
    "        self.trainable = is_trainable\n",
    "\n",
    "        self.data = [tokenizer(text, padding='max_length', max_length=235, truncation=True, add_special_tokens=True, return_tensors='pt') for text in data.values]\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.trainable:\n",
    "            target = torch.tensor(self.labels.values[idx])\n",
    "            return sample, target\n",
    "\n",
    "        else: \n",
    "            return sample, torch.tensor([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395790cd-095c-42fe-a70f-38a3d455b4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,  1521,  8340,  2051,    35,  3614,    18,  1460,    18,    35,\n",
      "          3614,  1521,  2118,  2847,  6076,  1891,   823,  1689, 10554,  1902,\n",
      "         13964,  1521,  8240,  2847,  5882,  2299,   746,  1565,  6186,   859,\n",
      "          2918,  2203,    18,  1058,    35,  4766,    18,    35,  1460, 12803,\n",
      "            18,  1460, 14670,  2411,  4181, 13911,  2377,  2052,  5429,  2173,\n",
      "          2112,  4224,  1460,   717,  2138, 11287,    18,  5057,   732,   676,\n",
      "          2126,  2073,   732,  2116,  1889, 23548,  3770,  1889,  2259,  2180,\n",
      "          2275,    18, 22819,  1513,  2118,    35,  4785,  1565,  2259,  2180,\n",
      "          2259, 16733,    18,  1058,  2315,   743,  2116,  1085,  2449,  2918,\n",
      "          6076,   732,  2116, 24786,  3254,  2062,   743, 11287,  2776,  2318,\n",
      "         10604,  5110,  2118,    18,    35, 16733,    18,  3839, 27841,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset_train, dataset_val = train_test_split(train_df, test_size = 0.2, shuffle = True, random_state = 42)\n",
    "\n",
    "train_dataset = CleanTalkDataset(dataset_train['conversation'],dataset_train['class'], True, tokenizer)\n",
    "val_dataset = CleanTalkDataset(dataset_val['conversation'], dataset_val['class'], True, tokenizer)\n",
    "\n",
    "for text, label  in train_dataset:\n",
    "\n",
    "    print(text)\n",
    "    print(label)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9420da21-6e6b-44b3-9cab-242dccf73ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 235])\n",
      "torch.Size([64, 1, 235])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=64,shuffle=False)\n",
    "\n",
    "for text, label in train_dataloader:\n",
    "    print(text['input_ids'].size())\n",
    "    print(text['attention_mask'].size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4f624-c95f-42f4-8545-a3e8ade09869",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af520b7-4483-4f44-808f-a0fa8d5be550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def model_train(model, train_dataloader, val_dataloader, learning_rate, epochs, patiece, model_nm):\n",
    "    best_acc = 0\n",
    "    early_stopping_threshold_count = 0\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)  # cuda 또는 cpu 출력\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_acc_train = []\n",
    "    total_loss_train = []\n",
    "    total_acc_val = []\n",
    "    total_loss_val = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        train_loss_=0.0\n",
    "        total = 0.0\n",
    "        correct = 0.0\n",
    "        \n",
    "        model.train() # sets into the training mode\n",
    "        \n",
    "        for train_input, label in tqdm(train_dataloader):\n",
    "            attention_mask = train_input['attention_mask'].squeeze(1).to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(input_ids, attention_mask) # from the forward function\n",
    "            #print(output[0])\n",
    "            loss = criterion(output.logits, label) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_ += loss.item()\n",
    "\n",
    "            preds = output[0].argmax(dim=-1)\n",
    "            correct += (preds == label).sum().item()\n",
    "            #correct += calc_accuracy(output[0], label)\n",
    "            total += label.size(0)\n",
    "            \n",
    "        total_loss_train.append(train_loss_ / len(train_dataloader))\n",
    "        total_acc_train.append(correct / total)\n",
    "        \n",
    "        print(f'Epochs: {epoch + 1} '\n",
    "              f'| Train Loss: {total_loss_train[-1] : .3f} '\n",
    "              f'| Train Accuracy: {total_acc_train[-1] : .3f} ')\n",
    "\n",
    "        with torch.no_grad(): # since we should not change gradient for validation \n",
    "\n",
    "            val_loss = 0.0\n",
    "            val_total = 0.0\n",
    "            val_correct = 0.0\n",
    "            \n",
    "            model.eval() # deactivate training\n",
    "            \n",
    "            # same process as the above\n",
    "            for val_input, label in tqdm(val_dataloader):\n",
    "                attention_mask = val_input['attention_mask'].squeeze(1).to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                label = label.to(device)\n",
    "                \n",
    "                output = model(input_ids, attention_mask) # from the forward function\n",
    "\n",
    "                loss = criterion(output.logits, label) \n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = output[0].argmax(dim=-1)\n",
    "                val_correct += (preds == label).sum().item()\n",
    "                val_total += label.size(0)\n",
    "                \n",
    "        total_loss_val.append(val_loss / len(val_dataloader))\n",
    "        total_acc_val.append(val_correct / val_total)\n",
    "            \n",
    "        print(\n",
    "              f'| Val Loss: {total_loss_val[-1]: .3f} '\n",
    "              f'| Val Accuracy: {total_acc_val[-1]: .3f}')\n",
    "            \n",
    "        if best_acc < total_acc_val[-1]:\n",
    "            best_acc = total_acc_val[-1] # saving only the best one\n",
    "            torch.save(model,f\"{model_nm}.pt\")\n",
    "            print(\"Saved model\")\n",
    "            early_stopping_threshold_count = 0\n",
    "        else:\n",
    "            early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n",
    "            \n",
    "        if early_stopping_threshold_count >= patience: # ==> patience=1\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return total_loss_train, total_acc_train, total_loss_val, total_acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44cdba40-1440-472f-8fcd-10093edb4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.167 | Train Accuracy:  0.619 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Val Loss:  0.681 | Val Accuracy:  0.818\n",
      "Saved model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:59<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.511 | Train Accuracy:  0.861 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Val Loss:  0.412 | Val Accuracy:  0.867\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "model = roberta_model\n",
    "model_nm = 'third_model' # 저장할 모델 이름\n",
    "learning_rate = 0.00001\n",
    "epochs = 2\n",
    "patience = 5\n",
    "\n",
    "total_loss_train, total_acc_train, total_loss_val, total_acc_val = model_train(model, train_dataloader, val_dataloader, learning_rate, epochs, patience, model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b326586-1f35-45da-b456-25d0eff89446",
   "metadata": {},
   "source": [
    "## 모델 history 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed04c0a-3bb4-48ba-bfef-d202968cb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "history = {'train_acc': total_acc_train}\n",
    "history['train_loss'] = total_loss_train\n",
    "history['val_acc'] = total_acc_val\n",
    "history['val_loss'] = total_loss_val\n",
    "\n",
    "# save data\n",
    "with open('model_history.pickle','wb') as fw:\n",
    "    pickle.dump(history, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50d00a-7b75-4b3e-88c9-e6537f5b1f09",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77688654-7dfe-484c-92a9-c8b5449ea576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 235])\n",
      "torch.Size([1, 235])\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CleanTalkDataset(test_df['conversation'],None, False,tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=64,shuffle=False)\n",
    "\n",
    "for text, label in test_dataset:\n",
    "    print(text['input_ids'].size())\n",
    "    print(text['attention_mask'].size())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ac1c1-0126-484a-8866-85d9e0b89e53",
   "metadata": {},
   "source": [
    "## 저장한 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8da36f3e-5661-4dd1-82be-170625892beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\"third_model.pt\", map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10559e47-3287-45cf-bdfc-7b434c43be06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predict_list = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "    for test_input, _ in test_dataloader:\n",
    "        attention_mask = test_input['attention_mask'].squeeze(1).to(device)\n",
    "        input_ids = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_ids, attention_mask) # from the forward function\n",
    "        preds = output[0].argmax(dim=-1)\n",
    "        predict_list.append(preds)\n",
    "        \n",
    "predict_list = torch.cat(predict_list).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19cb45-3967-483a-bc17-6d673e73295a",
   "metadata": {},
   "source": [
    "## Submission 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6c6067c-90d2-4239-8a61-d4c308c8b349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>t_495</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>t_496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>t_497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>t_498</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>t_499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx  class\n",
       "0    t_000      1\n",
       "1    t_001      2\n",
       "2    t_002      2\n",
       "3    t_003      3\n",
       "4    t_004      3\n",
       "..     ...    ...\n",
       "495  t_495      2\n",
       "496  t_496      2\n",
       "497  t_497      1\n",
       "498  t_498      2\n",
       "499  t_499      0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['class'] = predict_list\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99ddee57-dbf4-4349-b6ec-b953220fc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"0211_3_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9008dbc-ca5b-4f06-a7cd-bb4e361eaf49",
   "metadata": {},
   "source": [
    "### GPU 메모리 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "457a0e5d-8451-4780-8f57-03e3a27984a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
