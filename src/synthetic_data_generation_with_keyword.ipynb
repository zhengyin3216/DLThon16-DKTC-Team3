{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d71242-d341-4a58-ba1c-39b831c7feee",
   "metadata": {},
   "source": [
    "# **합성데이터 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86442453-cf70-4a91-bc08-10c372a7006e",
   "metadata": {},
   "source": [
    "## **모델 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550b9382-6585-4d18-819f-ae4b1c5f3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae79eb109c28428fb327bad68c49f90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010dba7b018a4cd7bdb13f7b56a16931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-AICA-5B'\n",
    "# model_id = 'MLP-KTLim/llama-3-Korean-Bllossom-8B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# 하단의 \"가중치 로딩 리포트(경고)\"는 텍스트만 생성할 경우 무시해도 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19425f9-260b-4366-9391-aa038f8298a6",
   "metadata": {},
   "source": [
    "## **텍스트 생성함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4e31c0-2f55-4ae3-b78c-a5aff8ab5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAugmentation(model, PROMPT, FEWSHOT, topic, instruction):\n",
    "    import time\n",
    "    import torch\n",
    "\n",
    "    # torch.cuda.synchronize()   # ✅ GPU 대기\n",
    "    # start_time = time.time()\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "        [{topic}] {instruction}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": PROMPT},\n",
    "        {\"role\": \"user\", \"content\": FEWSHOT},\n",
    "        {\"role\": \"user\", \"content\": instruction},\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    enc = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    \n",
    "    \n",
    "    terminators = [\n",
    "        tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\"),\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=enc[\"input_ids\"],\n",
    "        attention_mask=enc.get(\"attention_mask\", None),\n",
    "        \n",
    "        # 길이 제어 (6줄 대화 최적)\n",
    "        max_new_tokens=128,  \n",
    "        \n",
    "        # 샘플링 설정\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "\n",
    "        # 반복 방지\n",
    "        repetition_penalty=1.05,\n",
    "\n",
    "        # 종료 / 패딩\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "        # pad_token_id=tokenizer.eos_token_id  # 추가\n",
    "    )\n",
    "    \n",
    "    prompt_len = enc[\"input_ids\"].shape[-1]\n",
    "\n",
    "    result = tokenizer.decode(outputs[0][prompt_len:], skip_special_tokens=True)\n",
    "\n",
    "    # torch.cuda.synchronize()   # ✅ 다시 대기\n",
    "    # end_time = time.time()\n",
    "    \n",
    "    # elapsed = end_time - start_time\n",
    "    # print(f\"⏱ GPU 포함 실행 시간: {elapsed:.3f}초\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696b9dd-918c-49eb-ac70-9830901df731",
   "metadata": {},
   "source": [
    "## **프롬프트 작성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0e06ff-d41c-4b23-aae3-2fee7c6d3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "너는 한국어 대화문을 생성하는 역할이다.\n",
    "\n",
    "규칙:\n",
    "1. 반드시 한국어로 작성한다.\n",
    "2. 화자 이름은 쓰지 마.\n",
    "3. 자연스럽고 상황에 맞는 말투(반말, 존댓말)로 대화해.\n",
    "4. 6줄 이내로 작성한다.\n",
    "5. \"답변예시\", \"예시\", \"설명\" 같은 문구를 절대 쓰지 않는다.\n",
    "5. 예시의 문장, 표현을 그대로 사용 금지.\n",
    "6. 예시에서 나온 고유 단어 사용 금지.\n",
    "7. 대화문만 출력한다.\n",
    "\"\"\"\n",
    "\n",
    "FEWSHOT = \"\"\"\n",
    "질문 예:\n",
    "[주말 계획] 이 키워드를 중심으로 답변예시의 형식만 참고해서 6줄의 한국어 대화문 1개 만들어줘.\n",
    "\n",
    "답변 예:\n",
    "이번 주말에 뭐 할까?\n",
    "영화 한 편 보는 건 어때?\n",
    "그럼 내가 예매할게.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"이 키워드를 주제로 6줄의 한국어 대화문 1개 만들어줘.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf7d5fb-0a1c-43fe-a499-9069271b9185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11201/4166457105.py:33: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:347.)\n",
      "  input_ids=enc[\"input_ids\"],\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 테스트\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtextAugmentation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mFEWSHOT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFEWSHOT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m책\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstruction\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtextAugmentation\u001b[39m\u001b[34m(model, PROMPT, FEWSHOT, topic, instruction)\u001b[39m\n\u001b[32m     19\u001b[39m enc = tokenizer.apply_chat_template(\n\u001b[32m     20\u001b[39m     messages,\n\u001b[32m     21\u001b[39m     add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     22\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m ).to(model.device)\n\u001b[32m     27\u001b[39m terminators = [\n\u001b[32m     28\u001b[39m     tokenizer.convert_tokens_to_ids(\u001b[33m\"\u001b[39m\u001b[33m<|end_of_text|>\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     29\u001b[39m     tokenizer.convert_tokens_to_ids(\u001b[33m\"\u001b[39m\u001b[33m<|eot_id|>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m ]\n\u001b[32m     32\u001b[39m outputs = model.generate(\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     input_ids=\u001b[43menc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     34\u001b[39m     attention_mask=enc.get(\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# 길이 제어 (6줄 대화 최적)\u001b[39;00m\n\u001b[32m     37\u001b[39m     max_new_tokens=\u001b[32m128\u001b[39m,  \n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# 샘플링 설정\u001b[39;00m\n\u001b[32m     40\u001b[39m     do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     41\u001b[39m     temperature=\u001b[32m0.6\u001b[39m,\n\u001b[32m     42\u001b[39m     top_p=\u001b[32m0.9\u001b[39m,\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# 반복 방지\u001b[39;00m\n\u001b[32m     45\u001b[39m     repetition_penalty=\u001b[32m1.05\u001b[39m,\n\u001b[32m     46\u001b[39m \n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# 종료 / 패딩\u001b[39;00m\n\u001b[32m     48\u001b[39m     eos_token_id=terminators,\n\u001b[32m     49\u001b[39m     pad_token_id=tokenizer.eos_token_id\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# pad_token_id=tokenizer.eos_token_id  # 추가\u001b[39;00m\n\u001b[32m     51\u001b[39m )\n\u001b[32m     53\u001b[39m prompt_len = enc[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]\n\u001b[32m     55\u001b[39m result = tokenizer.decode(outputs[\u001b[32m0\u001b[39m][prompt_len:], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mIndexError\u001b[39m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "\n",
    "print(\n",
    "    textAugmentation(\n",
    "        model=model,\n",
    "        PROMPT=PROMPT,\n",
    "        FEWSHOT=FEWSHOT,\n",
    "        topic=\"책\",\n",
    "        instruction=instruction\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cb632-8781-4ae2-999e-83fd732f6a3f",
   "metadata": {},
   "source": [
    "## **키워드 추출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950b32e1-52f5-4f62-b8af-233f6df59f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword(file_path):\n",
    "    import csv\n",
    "    from collections import Counter\n",
    "    \n",
    "    keyword_list = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        reader = csv.DictReader(f)  # 컬럼명 기준 접근\n",
    "    \n",
    "        for i, row in enumerate(reader):\n",
    "            keywords = row[\"keywords\"]   # keywords 컬럼 접근\n",
    "            \n",
    "            keyword_list += keywords.split(\"\\n\")\n",
    "\n",
    "        counter = Counter(keyword_list)\n",
    "        # results = [k for k, _ in counter.most_common(max_len)]\n",
    "        \n",
    "        return dict(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae07428f-5465-42ee-8a1f-b7d51096963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_keywords(freq_dict, k=5000, alpha=0.5, min_freq=2):\n",
    "    \"\"\"\n",
    "    freq_dict: {keyword: frequency}\n",
    "    k       : 뽑을 키워드 개수 (중복 허용; Counter 기반이면 키 자체는 중복 없음)\n",
    "    alpha   : 빈도 스무딩 지수 (0=균등 랜덤, 1=빈도 그대로, 0.5=제곱근 스무딩 추천)\n",
    "    \"\"\"\n",
    "    # 빈도 필터링\n",
    "    filtered = {\n",
    "        k: v for k, v in freq_dict.items()\n",
    "        if v >= min_freq\n",
    "    }\n",
    "    \n",
    "    keywords = list(filtered.keys())\n",
    "    freqs = list(filtered.values())\n",
    "\n",
    "    # 빈도 스무딩(쏠림 완화)\n",
    "    weights = [f ** alpha for f in freqs]\n",
    "\n",
    "    # 가중치 기반 랜덤 샘플링\n",
    "    return random.choices(keywords, weights=weights, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d40d52-99e4-4c8b-9ed5-e37aa379cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 키워드 수:  5000\n",
      "중복 제거 키워드 수:  711\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/train_with_keywords.csv\"\n",
    "\n",
    "counter = get_keyword(file_path)\n",
    "keyword_list = sample_keywords(counter, k=5000, alpha=0.5, min_freq=3)\n",
    "print(\"전체 키워드 수: \", len(keyword_list))\n",
    "print(\"중복 제거 키워드 수: \", len(set(keyword_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ed980-564a-4695-9299-6b1daddc70c4",
   "metadata": {},
   "source": [
    "## **기본 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c08a4-bc78-4c5b-b106-311d6650ffb6",
   "metadata": {},
   "source": [
    "### **전처리 항목**\n",
    "- 줄바꿈(\"\\n\") -> 공백(\" \")\n",
    "- 쉼표(\",\") 제거\n",
    "- 공백 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7821b9-4c7a-4eea-82cb-f964e8ae7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_conversation(text: str) -> str:\n",
    "    # 줄바꿈 제거 + 쉼표 제거 + 공백 정리\n",
    "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    text = text.replace(\",\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46b6c6-5d0f-42fc-933a-ed270fb8f667",
   "metadata": {},
   "source": [
    "## **파일 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63313f2d-0aff-44c2-985e-295e3449d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def chunk_filename(base: str, chunk_id: int) -> str:\n",
    "    # 옵션 A: 4자리 청크 번호\n",
    "    return f\"{base}_{chunk_id:03d}.csv\"\n",
    "\n",
    "def write_generations_chunked(\n",
    "    model,\n",
    "    PROMPT,\n",
    "    FEWSHOT,\n",
    "    instruction,\n",
    "    out_dir=\"../data\",\n",
    "    base_name=\"general_conversations\",\n",
    "    chunk_size=1000,\n",
    "    start_idx=0,\n",
    "    start_chunk=1,\n",
    "    keyword_list=[]\n",
    "):\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    idx = start_idx\n",
    "    chunk_id = start_chunk\n",
    "    in_chunk_count = 0\n",
    "\n",
    "    f = None\n",
    "    writer = None\n",
    "\n",
    "    def open_new_chunk(chunk_id):\n",
    "        path = Path(out_dir) / chunk_filename(base_name, chunk_id)\n",
    "        f = open(path, \"w\", newline=\"\", encoding=\"utf-8-sig\")\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"idx\", \"class\", \"conversation\"])\n",
    "        return f, w, str(path)\n",
    "\n",
    "    f, writer, current_path = open_new_chunk(chunk_id)\n",
    "\n",
    "\n",
    "    \n",
    "    for keyword in keyword_list:\n",
    "        # 진행상황 표시\n",
    "        if idx % chunk_size == 0:\n",
    "            print(\"In progress:\", current_path)\n",
    "        \n",
    "        gen = textAugmentation(model, PROMPT, FEWSHOT, keyword, instruction)\n",
    "        \n",
    "        conv = clean_conversation(gen)\n",
    "        writer.writerow([idx, \"일반\", conv])\n",
    "\n",
    "        idx += 1\n",
    "        in_chunk_count += 1\n",
    "\n",
    "        if in_chunk_count == chunk_size:\n",
    "            f.close()\n",
    "            chunk_id += 1\n",
    "            in_chunk_count = 0  # chunk size까지 저장 후 다시 0으로 초기화\n",
    "            print(\"Complete:\", current_path)\n",
    "            f, writer, current_path = open_new_chunk(chunk_id)\n",
    "            \n",
    "    if f:\n",
    "        f.close()\n",
    "\n",
    "    return idx, chunk_id  # 다음 이어쓰기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaef0981-a1d1-4528-be08-a6bcd12d5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: ../data/general_conversations_with_keyword_001.csv\n",
      "Complete: ../data/general_conversations_with_keyword_001.csv\n",
      "In progress: ../data/general_conversations_with_keyword_002.csv\n",
      "Complete: ../data/general_conversations_with_keyword_002.csv\n",
      "In progress: ../data/general_conversations_with_keyword_003.csv\n",
      "Complete: ../data/general_conversations_with_keyword_003.csv\n",
      "In progress: ../data/general_conversations_with_keyword_004.csv\n",
      "Complete: ../data/general_conversations_with_keyword_004.csv\n",
      "In progress: ../data/general_conversations_with_keyword_005.csv\n",
      "Complete: ../data/general_conversations_with_keyword_005.csv\n"
     ]
    }
   ],
   "source": [
    "idx, chunk_id = write_generations_chunked(\n",
    "    model=model,\n",
    "    PROMPT=PROMPT,\n",
    "    FEWSHOT=FEWSHOT,\n",
    "    instruction=instruction,\n",
    "    out_dir=\"../data\",\n",
    "    base_name=\"general_conversations_with_keyword\",\n",
    "    chunk_size=1000,\n",
    "    start_idx=0,\n",
    "    start_chunk=1,\n",
    "    keyword_list=keyword_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7dff7-76b8-40b2-8f9d-13afff951c6c",
   "metadata": {},
   "source": [
    "## **8개 분류, 각각 10개 세부 주제 (ChapGPT 생성)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e59c072-9276-42f4-a276-228744a41dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "TOPICS = [\n",
    "    # 음식·식사\n",
    "    \"점심 메뉴 못 정해서 고민\",\n",
    "    \"혼밥 vs 같이 먹기\",\n",
    "    \"배달앱 메뉴 추천 요청\",\n",
    "    \"비 오는 날 음식 고르기\",\n",
    "    \"다이어트 중 메뉴 고민\",\n",
    "    \"야식 먹을지 말지 고민\",\n",
    "    \"회사 근처 맛집 이야기\",\n",
    "    \"집에 재료 없을 때 요리 고민\",\n",
    "    \"카페 메뉴 고르기\",\n",
    "    \"신메뉴 후기 공유\",\n",
    "\n",
    "    # 컨디션·생활\n",
    "    \"야근 후 너무 피곤함\",\n",
    "    \"잠 설쳐서 졸림\",\n",
    "    \"감기 기운 있음\",\n",
    "    \"운동 시작했는데 힘듦\",\n",
    "    \"허리나 목 통증\",\n",
    "    \"스트레스 받아서 지침\",\n",
    "    \"주말에 몰아서 잠 자기\",\n",
    "    \"불면증 고민\",\n",
    "    \"체력 떨어진 느낌\",\n",
    "    \"건강검진 결과 이야기\",\n",
    "\n",
    "    # 약속·이동\n",
    "    \"약속 시간 변경 요청\",\n",
    "    \"지각해서 사과 연락\",\n",
    "    \"길 막혀서 늦음\",\n",
    "    \"만날 장소 헷갈림\",\n",
    "    \"어디쯤 왔는지 확인\",\n",
    "    \"약속 취소 상황\",\n",
    "    \"비 와서 약속 고민\",\n",
    "    \"막차 걱정\",\n",
    "    \"주차 자리 못 찾음\",\n",
    "    \"귀가 중 통화\",\n",
    "\n",
    "    # 감정·관계\n",
    "    \"상사 때문에 스트레스\",\n",
    "    \"친구와 싸운 후 고민\",\n",
    "    \"연인과 오해 발생\",\n",
    "    \"시험이나 면접 불안\",\n",
    "    \"실패해서 우울함\",\n",
    "    \"잘한 일 자랑\",\n",
    "    \"위로 요청\",\n",
    "    \"자신감 부족\",\n",
    "    \"진로 고민\",\n",
    "    \"번아웃 상태\",\n",
    "\n",
    "    # 소비·서비스\n",
    "    \"음식 배달 지연 항의\",\n",
    "    \"상품 불량 교환 문의\",\n",
    "    \"환불 규정 질문\",\n",
    "    \"예약 변경 요청\",\n",
    "    \"택배 분실 문의\",\n",
    "    \"쿠폰 사용법 질문\",\n",
    "    \"포인트 적립 문의\",\n",
    "    \"영수증 재발급 요청\",\n",
    "    \"가격 비교 상담\",\n",
    "    \"AS 접수 문의\",\n",
    "\n",
    "    # 전화·메신저\n",
    "    \"부재중 전화 해명\",\n",
    "    \"배터리 없어서 급통화\",\n",
    "    \"통화 소리 끊김 문제\",\n",
    "    \"끊긴 전화 재연결\",\n",
    "    \"늦은 밤 전화 사과\",\n",
    "    \"급하게 위치 물어봄\",\n",
    "    \"운전 중 통화\",\n",
    "    \"잘못 걸린 전화\",\n",
    "    \"문자 vs 통화 선택\",\n",
    "    \"통화 소리가 작은 문제\",\n",
    "\n",
    "    # 긴급·문제\n",
    "    \"지갑 분실\",\n",
    "    \"휴대폰 분실\",\n",
    "    \"교통사고 목격\",\n",
    "    \"차 고장\",\n",
    "    \"집 열쇠 분실\",\n",
    "    \"길 잃음\",\n",
    "    \"카드 분실 신고\",\n",
    "    \"사기 의심 상황\",\n",
    "    \"소음 신고\",\n",
    "    \"위급 상황 신고\",\n",
    "\n",
    "    # 취미 생활\n",
    "    \"요즘 취미생활 뭐 하는지 이야기\",\n",
    "    \"새로운 취미 시작 고민\",\n",
    "    \"운동을 취미로 시작한 이야기\",\n",
    "    \"게임을 취미로 즐기는 이야기\",\n",
    "    \"드라마나 영화 보는 취미\",\n",
    "    \"음악 듣기나 연주 취미 이야기\",\n",
    "    \"책 읽는 취미 이야기\",\n",
    "    \"사진이나 영상 찍는 취미\",\n",
    "    \"요리나 베이킹 취미 이야기\",\n",
    "    \"혼자 즐기는 취미생활 이야기\"\n",
    "]\n",
    "\n",
    "topic_list = random.choices(TOPICS, k=5000)\n",
    "len(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0a1817-3653-4546-b375-2ac3000495b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "너는 한국어 대화문을 생성하는 역할이다.\n",
    "\n",
    "규칙:\n",
    "1. 반드시 한국어로 작성한다.\n",
    "2. 화자 이름은 쓰지 마.\n",
    "3. 자연스럽고 상황에 맞는 말투(반말, 존댓말)로 대화해.\n",
    "4. 6줄 이내로 작성한다.\n",
    "5. \"답변예시\", \"예시\", \"설명\" 같은 문구를 절대 쓰지 않는다.\n",
    "5. 예시의 문장, 표현을 그대로 사용 금지.\n",
    "6. 예시에서 나온 고유 단어 사용 금지.\n",
    "7. 대화문만 출력한다.\n",
    "\"\"\"\n",
    "\n",
    "FEWSHOT = \"\"\"\n",
    "질문 예:\n",
    "[주말 계획] 이것을 주제로 6줄의 한국어 대화문 1개 만들어줘.\n",
    "\n",
    "답변 예:\n",
    "이번 주말에 뭐 할까?\n",
    "영화 한 편 보는 건 어때?\n",
    "그럼 내가 예매할게.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"이것을 주제로 6줄의 한국어 대화문 1개 만들어줘.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1564697d-9ec5-4ad7-b981-3ae6e2c6d307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: ../data/general_conversations_001.csv\n",
      "Complete: ../data/general_conversations_001.csv\n",
      "In progress: ../data/general_conversations_002.csv\n",
      "Complete: ../data/general_conversations_002.csv\n",
      "In progress: ../data/general_conversations_003.csv\n",
      "Complete: ../data/general_conversations_003.csv\n",
      "In progress: ../data/general_conversations_004.csv\n",
      "Complete: ../data/general_conversations_004.csv\n",
      "In progress: ../data/general_conversations_005.csv\n",
      "Complete: ../data/general_conversations_005.csv\n"
     ]
    }
   ],
   "source": [
    "idx, chunk_id = write_generations_chunked(\n",
    "    model=model,\n",
    "    PROMPT=PROMPT,\n",
    "    FEWSHOT=FEWSHOT,\n",
    "    instruction=instruction,\n",
    "    out_dir=\"../data\",\n",
    "    base_name=\"general_conversations\",\n",
    "    chunk_size=1000,\n",
    "    start_idx=0,\n",
    "    start_chunk=1,\n",
    "    keyword_list=topic_list\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aiffel_learning_py312)",
   "language": "python",
   "name": "aiffel_learning_py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
