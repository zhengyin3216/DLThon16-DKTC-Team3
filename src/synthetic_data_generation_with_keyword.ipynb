{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d71242-d341-4a58-ba1c-39b831c7feee",
   "metadata": {},
   "source": [
    "# **합성데이터 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86442453-cf70-4a91-bc08-10c372a7006e",
   "metadata": {},
   "source": [
    "## **모델 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550b9382-6585-4d18-819f-ae4b1c5f3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ff53427b6d4028bf0679e13117b3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a4177bc595457abc3a8fe056fbb08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b6e595125a49999ce93279f9307e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mMllamaForCausalLM LOAD REPORT\u001b[0m from: Bllossom/llama-3.2-Korean-Bllossom-AICA-5B\n",
      "Key                                                                                             | Status     |  | \n",
      "------------------------------------------------------------------------------------------------+------------+--+-\n",
      "vision_model.transformer.layers.{0...31}.input_layernorm.weight                                 | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.self_attn.k_proj.weight                                | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.mlp.fc2.weight                                         | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.input_layernorm.bias                                   | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.self_attn.v_proj.weight                                | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.o_proj.weight         | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.self_attn.q_proj.weight                                | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.post_attention_layernorm.weight                        | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.mlp.fc2.bias                                           | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.mlp.fc1.bias                                           | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.post_attention_layernorm.bias                          | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.self_attn.o_proj.weight                                | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.gate_ffn                        | UNEXPECTED |  | \n",
      "vision_model.transformer.layers.{0...31}.mlp.fc1.weight                                         | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc2.bias                    | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc1.bias                    | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.q_proj.weight         | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.input_layernorm.bias            | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc2.weight                  | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.v_proj.weight         | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc1.weight                  | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.gate_attn                       | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.k_proj.weight         | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.post_attention_layernorm.weight | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.input_layernorm.weight          | UNEXPECTED |  | \n",
      "vision_model.gated_positional_embedding.gate                                                    | UNEXPECTED |  | \n",
      "vision_model.pre_tile_positional_embedding.embedding.weight                                     | UNEXPECTED |  | \n",
      "vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.post_attention_layernorm.bias   | UNEXPECTED |  | \n",
      "vision_model.layernorm_pre.bias                                                                 | UNEXPECTED |  | \n",
      "vision_model.patch_embedding.weight                                                             | UNEXPECTED |  | \n",
      "multi_modal_projector.bias                                                                      | UNEXPECTED |  | \n",
      "vision_model.class_embedding                                                                    | UNEXPECTED |  | \n",
      "vision_model.gated_positional_embedding.tile_embedding.weight                                   | UNEXPECTED |  | \n",
      "vision_model.post_tile_positional_embedding.gate                                                | UNEXPECTED |  | \n",
      "vision_model.gated_positional_embedding.embedding                                               | UNEXPECTED |  | \n",
      "vision_model.layernorm_post.weight                                                              | UNEXPECTED |  | \n",
      "vision_model.layernorm_post.bias                                                                | UNEXPECTED |  | \n",
      "vision_model.pre_tile_positional_embedding.gate                                                 | UNEXPECTED |  | \n",
      "vision_model.layernorm_pre.weight                                                               | UNEXPECTED |  | \n",
      "multi_modal_projector.weight                                                                    | UNEXPECTED |  | \n",
      "vision_model.post_tile_positional_embedding.embedding.weight                                    | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-AICA-5B'\n",
    "# model_id = 'MLP-KTLim/llama-3-Korean-Bllossom-8B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# 하단의 \"가중치 로딩 리포트(경고)\"는 텍스트만 생성할 경우 무시해도 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19425f9-260b-4366-9391-aa038f8298a6",
   "metadata": {},
   "source": [
    "## **텍스트 생성함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4e31c0-2f55-4ae3-b78c-a5aff8ab5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAugmentation(model, PROMPT, FEWSHOT, topic, instruction):\n",
    "    import time\n",
    "    import torch\n",
    "\n",
    "    # torch.cuda.synchronize()   # ✅ GPU 대기\n",
    "    # start_time = time.time()\n",
    "\n",
    "    instruction = f\"\"\"\n",
    "        [{topic}] {instruction}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": PROMPT},\n",
    "        {\"role\": \"user\", \"content\": FEWSHOT},\n",
    "        {\"role\": \"user\", \"content\": instruction},\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    enc = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    \n",
    "    \n",
    "    terminators = [\n",
    "        tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\"),\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=enc[\"input_ids\"],\n",
    "        attention_mask=enc.get(\"attention_mask\", None),\n",
    "        \n",
    "        # 길이 제어 (6줄 대화 최적)\n",
    "        max_new_tokens=128,  \n",
    "        \n",
    "        # 샘플링 설정\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "\n",
    "        # 반복 방지\n",
    "        repetition_penalty=1.05,\n",
    "\n",
    "        # 종료 / 패딩\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "        # pad_token_id=tokenizer.eos_token_id  # 추가\n",
    "    )\n",
    "    \n",
    "    prompt_len = enc[\"input_ids\"].shape[-1]\n",
    "\n",
    "    result = tokenizer.decode(outputs[0][prompt_len:], skip_special_tokens=True)\n",
    "\n",
    "    # torch.cuda.synchronize()   # ✅ 다시 대기\n",
    "    # end_time = time.time()\n",
    "    \n",
    "    # elapsed = end_time - start_time\n",
    "    # print(f\"⏱ GPU 포함 실행 시간: {elapsed:.3f}초\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696b9dd-918c-49eb-ac70-9830901df731",
   "metadata": {},
   "source": [
    "## **프롬프트 작성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0e06ff-d41c-4b23-aae3-2fee7c6d3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "너는 한국어 대화문을 생성하는 역할이다.\n",
    "\n",
    "규칙:\n",
    "1. 반드시 한국어로 작성한다.\n",
    "2. 화자 이름은 쓰지 마.\n",
    "3. 자연스럽고 상황에 맞는 말투(반말, 존댓말)로 대화해.\n",
    "4. 6줄 이내로 작성한다.\n",
    "5. \"답변예시\", \"예시\", \"설명\" 같은 문구를 절대 쓰지 않는다.\n",
    "5. 예시의 문장, 표현을 그대로 사용 금지.\n",
    "6. 예시에서 나온 고유 단어 사용 금지.\n",
    "7. 대화문만 출력한다.\n",
    "\"\"\"\n",
    "\n",
    "FEWSHOT = \"\"\"\n",
    "질문 예:\n",
    "[주말 계획] 이 키워드를 중심으로 답변예시의 형식만 참고해서 6줄의 한국어 대화문 1개 만들어줘.\n",
    "\n",
    "답변 예:\n",
    "이번 주말에 뭐 할까?\n",
    "영화 한 편 보는 건 어때?\n",
    "그럼 내가 예매할게.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"이 키워드를 주제로 6줄의 한국어 대화문 1개 만들어줘.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf7d5fb-0a1c-43fe-a499-9069271b9185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "책 읽기 plan은 어떻게 되나요?\n",
      "저는 오늘부터 '왕좌의 게임'을 읽기로 했어요.\n",
      "그럼요, 정말 흥미롭게 봐야겠네요.\n",
      "처음 몇 권은 조금 어렵더라고요.\n",
      "그래서 천천히 읽으면서 알아가면 좋을 것 같아요.\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "\n",
    "print(\n",
    "    textAugmentation(\n",
    "        model=model,\n",
    "        PROMPT=PROMPT,\n",
    "        FEWSHOT=FEWSHOT,\n",
    "        topic=\"책\",\n",
    "        instruction=instruction\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039cb632-8781-4ae2-999e-83fd732f6a3f",
   "metadata": {},
   "source": [
    "## **키워드 추출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950b32e1-52f5-4f62-b8af-233f6df59f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword(file_path):\n",
    "    import csv\n",
    "    from collections import Counter\n",
    "    \n",
    "    keyword_list = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        reader = csv.DictReader(f)  # 컬럼명 기준 접근\n",
    "    \n",
    "        for i, row in enumerate(reader):\n",
    "            keywords = row[\"keywords\"]   # keywords 컬럼 접근\n",
    "            \n",
    "            keyword_list += keywords.split(\"\\n\")\n",
    "\n",
    "        counter = Counter(keyword_list)\n",
    "        # results = [k for k, _ in counter.most_common(max_len)]\n",
    "        \n",
    "        return dict(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae07428f-5465-42ee-8a1f-b7d51096963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_keywords(freq_dict, k=5000, alpha=0.5, min_freq=2):\n",
    "    \"\"\"\n",
    "    freq_dict: {keyword: frequency}\n",
    "    k       : 뽑을 키워드 개수 (중복 허용; Counter 기반이면 키 자체는 중복 없음)\n",
    "    alpha   : 빈도 스무딩 지수 (0=균등 랜덤, 1=빈도 그대로, 0.5=제곱근 스무딩 추천)\n",
    "    \"\"\"\n",
    "    # 빈도 필터링\n",
    "    filtered = {\n",
    "        k: v for k, v in freq_dict.items()\n",
    "        if v >= min_freq\n",
    "    }\n",
    "    \n",
    "    keywords = list(filtered.keys())\n",
    "    freqs = list(filtered.values())\n",
    "\n",
    "    # 빈도 스무딩(쏠림 완화)\n",
    "    weights = [f ** alpha for f in freqs]\n",
    "\n",
    "    # 가중치 기반 랜덤 샘플링\n",
    "    return random.choices(keywords, weights=weights, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d40d52-99e4-4c8b-9ed5-e37aa379cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 키워드 수:  5000\n",
      "중복 제거 키워드 수:  711\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/train_with_keywords.csv\"\n",
    "\n",
    "counter = get_keyword(file_path)\n",
    "keyword_list = sample_keywords(counter, k=5000, alpha=0.5, min_freq=3)\n",
    "print(\"전체 키워드 수: \", len(keyword_list))\n",
    "print(\"중복 제거 키워드 수: \", len(set(keyword_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ed980-564a-4695-9299-6b1daddc70c4",
   "metadata": {},
   "source": [
    "## **기본 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c08a4-bc78-4c5b-b106-311d6650ffb6",
   "metadata": {},
   "source": [
    "### **전처리 항목**\n",
    "- 줄바꿈(\"\\n\") -> 공백(\" \")\n",
    "- 쉼표(\",\") 제거\n",
    "- 공백 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7821b9-4c7a-4eea-82cb-f964e8ae7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_conversation(text: str) -> str:\n",
    "    # 줄바꿈 제거 + 쉼표 제거 + 공백 정리\n",
    "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "    text = text.replace(\",\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46b6c6-5d0f-42fc-933a-ed270fb8f667",
   "metadata": {},
   "source": [
    "## **파일 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63313f2d-0aff-44c2-985e-295e3449d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def chunk_filename(base: str, chunk_id: int) -> str:\n",
    "    # 옵션 A: 4자리 청크 번호\n",
    "    return f\"{base}_{chunk_id:03d}.csv\"\n",
    "\n",
    "def write_generations_chunked(\n",
    "    model,\n",
    "    PROMPT,\n",
    "    FEWSHOT,\n",
    "    instruction,\n",
    "    out_dir=\"../data\",\n",
    "    base_name=\"general_conversations\",\n",
    "    chunk_size=1000,\n",
    "    start_idx=0,\n",
    "    start_chunk=1,\n",
    "    keyword_list=[]\n",
    "):\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    idx = start_idx\n",
    "    chunk_id = start_chunk\n",
    "    in_chunk_count = 0\n",
    "\n",
    "    f = None\n",
    "    writer = None\n",
    "\n",
    "    def open_new_chunk(chunk_id):\n",
    "        path = Path(out_dir) / chunk_filename(base_name, chunk_id)\n",
    "        f = open(path, \"w\", newline=\"\", encoding=\"utf-8-sig\")\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"idx\", \"class\", \"conversation\"])\n",
    "        return f, w, str(path)\n",
    "\n",
    "    f, writer, current_path = open_new_chunk(chunk_id)\n",
    "\n",
    "\n",
    "    \n",
    "    for keyword in keyword_list:\n",
    "        # 진행상황 표시\n",
    "        if idx % chunk_size == 0:\n",
    "            print(\"In progress:\", current_path)\n",
    "        \n",
    "        gen = textAugmentation(model, PROMPT, FEWSHOT, keyword, instruction)\n",
    "        \n",
    "        conv = clean_conversation(gen)\n",
    "        writer.writerow([idx, \"일반\", conv])\n",
    "\n",
    "        idx += 1\n",
    "        in_chunk_count += 1\n",
    "\n",
    "        if in_chunk_count == chunk_size:\n",
    "            f.close()\n",
    "            chunk_id += 1\n",
    "            in_chunk_count = 0  # chunk size까지 저장 후 다시 0으로 초기화\n",
    "            print(\"Complete:\", current_path)\n",
    "            f, writer, current_path = open_new_chunk(chunk_id)\n",
    "            \n",
    "    if f:\n",
    "        f.close()\n",
    "\n",
    "    return idx, chunk_id  # 다음 이어쓰기용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaef0981-a1d1-4528-be08-a6bcd12d5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: ../data/general_conversations_with_keyword_001.csv\n",
      "Complete: ../data/general_conversations_with_keyword_001.csv\n",
      "In progress: ../data/general_conversations_with_keyword_002.csv\n",
      "Complete: ../data/general_conversations_with_keyword_002.csv\n",
      "In progress: ../data/general_conversations_with_keyword_003.csv\n",
      "Complete: ../data/general_conversations_with_keyword_003.csv\n",
      "In progress: ../data/general_conversations_with_keyword_004.csv\n",
      "Complete: ../data/general_conversations_with_keyword_004.csv\n",
      "In progress: ../data/general_conversations_with_keyword_005.csv\n",
      "Complete: ../data/general_conversations_with_keyword_005.csv\n"
     ]
    }
   ],
   "source": [
    "idx, chunk_id = write_generations_chunked(\n",
    "    model=model,\n",
    "    PROMPT=PROMPT,\n",
    "    FEWSHOT=FEWSHOT,\n",
    "    instruction=instruction,\n",
    "    out_dir=\"../data\",\n",
    "    base_name=\"general_conversations_with_keyword\",\n",
    "    chunk_size=1000,\n",
    "    start_idx=0,\n",
    "    start_chunk=1,\n",
    "    keyword_list=keyword_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7dff7-76b8-40b2-8f9d-13afff951c6c",
   "metadata": {},
   "source": [
    "## **8개 분류, 각각 10개 세부 주제 (ChapGPT 생성)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e59c072-9276-42f4-a276-228744a41dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "TOPICS = [\n",
    "    # 음식·식사\n",
    "    \"점심 메뉴 못 정해서 고민\",\n",
    "    \"혼밥 vs 같이 먹기\",\n",
    "    \"배달앱 메뉴 추천 요청\",\n",
    "    \"비 오는 날 음식 고르기\",\n",
    "    \"다이어트 중 메뉴 고민\",\n",
    "    \"야식 먹을지 말지 고민\",\n",
    "    \"회사 근처 맛집 이야기\",\n",
    "    \"집에 재료 없을 때 요리 고민\",\n",
    "    \"카페 메뉴 고르기\",\n",
    "    \"신메뉴 후기 공유\",\n",
    "\n",
    "    # 컨디션·생활\n",
    "    \"야근 후 너무 피곤함\",\n",
    "    \"잠 설쳐서 졸림\",\n",
    "    \"감기 기운 있음\",\n",
    "    \"운동 시작했는데 힘듦\",\n",
    "    \"허리나 목 통증\",\n",
    "    \"스트레스 받아서 지침\",\n",
    "    \"주말에 몰아서 잠 자기\",\n",
    "    \"불면증 고민\",\n",
    "    \"체력 떨어진 느낌\",\n",
    "    \"건강검진 결과 이야기\",\n",
    "\n",
    "    # 약속·이동\n",
    "    \"약속 시간 변경 요청\",\n",
    "    \"지각해서 사과 연락\",\n",
    "    \"길 막혀서 늦음\",\n",
    "    \"만날 장소 헷갈림\",\n",
    "    \"어디쯤 왔는지 확인\",\n",
    "    \"약속 취소 상황\",\n",
    "    \"비 와서 약속 고민\",\n",
    "    \"막차 걱정\",\n",
    "    \"주차 자리 못 찾음\",\n",
    "    \"귀가 중 통화\",\n",
    "\n",
    "    # 감정·관계\n",
    "    \"상사 때문에 스트레스\",\n",
    "    \"친구와 싸운 후 고민\",\n",
    "    \"연인과 오해 발생\",\n",
    "    \"시험이나 면접 불안\",\n",
    "    \"실패해서 우울함\",\n",
    "    \"잘한 일 자랑\",\n",
    "    \"위로 요청\",\n",
    "    \"자신감 부족\",\n",
    "    \"진로 고민\",\n",
    "    \"번아웃 상태\",\n",
    "\n",
    "    # 소비·서비스\n",
    "    \"음식 배달 지연 항의\",\n",
    "    \"상품 불량 교환 문의\",\n",
    "    \"환불 규정 질문\",\n",
    "    \"예약 변경 요청\",\n",
    "    \"택배 분실 문의\",\n",
    "    \"쿠폰 사용법 질문\",\n",
    "    \"포인트 적립 문의\",\n",
    "    \"영수증 재발급 요청\",\n",
    "    \"가격 비교 상담\",\n",
    "    \"AS 접수 문의\",\n",
    "\n",
    "    # 전화·메신저\n",
    "    \"부재중 전화 해명\",\n",
    "    \"배터리 없어서 급통화\",\n",
    "    \"통화 소리 끊김 문제\",\n",
    "    \"끊긴 전화 재연결\",\n",
    "    \"늦은 밤 전화 사과\",\n",
    "    \"급하게 위치 물어봄\",\n",
    "    \"운전 중 통화\",\n",
    "    \"잘못 걸린 전화\",\n",
    "    \"문자 vs 통화 선택\",\n",
    "    \"통화 소리가 작은 문제\",\n",
    "\n",
    "    # 긴급·문제\n",
    "    \"지갑 분실\",\n",
    "    \"휴대폰 분실\",\n",
    "    \"교통사고 목격\",\n",
    "    \"차 고장\",\n",
    "    \"집 열쇠 분실\",\n",
    "    \"길 잃음\",\n",
    "    \"카드 분실 신고\",\n",
    "    \"사기 의심 상황\",\n",
    "    \"소음 신고\",\n",
    "    \"위급 상황 신고\",\n",
    "\n",
    "    # 취미 생활\n",
    "    \"요즘 취미생활 뭐 하는지 이야기\",\n",
    "    \"새로운 취미 시작 고민\",\n",
    "    \"운동을 취미로 시작한 이야기\",\n",
    "    \"게임을 취미로 즐기는 이야기\",\n",
    "    \"드라마나 영화 보는 취미\",\n",
    "    \"음악 듣기나 연주 취미 이야기\",\n",
    "    \"책 읽는 취미 이야기\",\n",
    "    \"사진이나 영상 찍는 취미\",\n",
    "    \"요리나 베이킹 취미 이야기\",\n",
    "    \"혼자 즐기는 취미생활 이야기\"\n",
    "]\n",
    "\n",
    "topic_list = random.choices(TOPICS, k=5000)\n",
    "len(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0a1817-3653-4546-b375-2ac3000495b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "너는 한국어 대화문을 생성하는 역할이다.\n",
    "\n",
    "규칙:\n",
    "1. 반드시 한국어로 작성한다.\n",
    "2. 화자 이름은 쓰지 마.\n",
    "3. 자연스럽고 상황에 맞는 말투(반말, 존댓말)로 대화해.\n",
    "4. 6줄 이내로 작성한다.\n",
    "5. \"답변예시\", \"예시\", \"설명\" 같은 문구를 절대 쓰지 않는다.\n",
    "5. 예시의 문장, 표현을 그대로 사용 금지.\n",
    "6. 예시에서 나온 고유 단어 사용 금지.\n",
    "7. 대화문만 출력한다.\n",
    "\"\"\"\n",
    "\n",
    "FEWSHOT = \"\"\"\n",
    "질문 예:\n",
    "[주말 계획] 이것을 주제로 6줄의 한국어 대화문 1개 만들어줘.\n",
    "\n",
    "답변 예:\n",
    "이번 주말에 뭐 할까?\n",
    "영화 한 편 보는 건 어때?\n",
    "그럼 내가 예매할게.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"이것을 주제로 6줄의 한국어 대화문 1개 만들어줘.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1564697d-9ec5-4ad7-b981-3ae6e2c6d307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: ../data/general_conversations_001.csv\n",
      "Complete: ../data/general_conversations_001.csv\n",
      "In progress: ../data/general_conversations_002.csv\n",
      "Complete: ../data/general_conversations_002.csv\n",
      "In progress: ../data/general_conversations_003.csv\n",
      "Complete: ../data/general_conversations_003.csv\n",
      "In progress: ../data/general_conversations_004.csv\n",
      "Complete: ../data/general_conversations_004.csv\n",
      "In progress: ../data/general_conversations_005.csv\n",
      "Complete: ../data/general_conversations_005.csv\n"
     ]
    }
   ],
   "source": [
    "idx, chunk_id = write_generations_chunked(\n",
    "    model=model,\n",
    "    PROMPT=PROMPT,\n",
    "    FEWSHOT=FEWSHOT,\n",
    "    instruction=instruction,\n",
    "    out_dir=\"../data\",\n",
    "    base_name=\"general_conversations\",\n",
    "    chunk_size=1000,\n",
    "    start_idx=0,\n",
    "    start_chunk=1,\n",
    "    keyword_list=topic_list\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aiffel_learning_py312)",
   "language": "python",
   "name": "aiffel_learning_py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
